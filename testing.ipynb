{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def add_f1_scores(metrics: dict) -> dict:\n",
    "    \"\"\"Calculate and add F1 scores to a copy of the given metrics dictionary, keeping the desired order.\"\"\"\n",
    "    new_metrics = copy.deepcopy(metrics)  # Create a copy to avoid modifying the original\n",
    "\n",
    "    # Extract precision and recall for (B)\n",
    "    precision_B = new_metrics.get('metrics/precision(B)', 0)\n",
    "    recall_B = new_metrics.get('metrics/recall(B)', 0)\n",
    "    F1_B = 2 * (precision_B * recall_B) / (precision_B + recall_B) if (precision_B + recall_B) > 0 else 0\n",
    "\n",
    "    # Extract precision and recall for (M)\n",
    "    precision_M = new_metrics.get('metrics/precision(M)', 0)\n",
    "    recall_M = new_metrics.get('metrics/recall(M)', 0)\n",
    "    F1_M = 2 * (precision_M * recall_M) / (precision_M + recall_M) if (precision_M + recall_M) > 0 else 0\n",
    "\n",
    "    # Create a new dictionary with the desired order\n",
    "    ordered_metrics = {}\n",
    "    for key, value in new_metrics.items():\n",
    "        ordered_metrics[key] = value\n",
    "        if key == 'metrics/recall(B)':\n",
    "            ordered_metrics['metrics/F1_score(B)'] = np.float64(F1_B)\n",
    "        if key == 'metrics/recall(M)':\n",
    "            ordered_metrics['metrics/F1_score(M)'] = np.float64(F1_M)\n",
    "\n",
    "    return ordered_metrics\n",
    "\n",
    "\n",
    "def safe_validate(model_path, extra_config):\n",
    "    model = YOLO(model_path, task=\"segment\")\n",
    "    val_metrics = model.val(**extra_config)\n",
    "    return val_metrics\n",
    "\n",
    "def validate_experiment(dataframe, parameters):\n",
    "    model_pt_path = parameters[\"model_pt_path\"]\n",
    "    validation_params = parameters[\"validation_params\"]\n",
    "    model_name = parameters[\"model_name\"]\n",
    "    dataset_name = parameters[\"dataset_name\"]\n",
    "    optimizer = parameters[\"optimizer\"]\n",
    "    model_format = parameters[\"format\"]\n",
    "    \n",
    "    val_results = safe_validate(model_pt_path, validation_params)\n",
    "    data = add_f1_scores(val_results.results_dict) | val_results.speed\n",
    "    cleaned_data = {key.replace(\"metrics/\", \"\"): value for key, value in data.items()}\n",
    "    cleaned_data.update(Model=model_name, Dataset=dataset_name, Optimizer=optimizer, Format=model_format)\n",
    "    row_data = pd.DataFrame([cleaned_data])\n",
    "    dataframe = pd.concat([dataframe, row_data], ignore_index=True)\n",
    "\n",
    "\n",
    "def validate_run(config_file, results_path):\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "        \n",
    "    dataframe = pd.DataFrame()\n",
    "\n",
    "    for key, config in config_dict.items():\n",
    "        dataset_name, temp = os.path.split(key)\n",
    "        model_name, optimizer = temp.split(\"_\")\n",
    "\n",
    "        hyperparams = config[\"hyperparams\"]\n",
    "        done = config[\"done\"]\n",
    "        trt32 = config[\"trt32\"]\n",
    "        trt16 = config[\"trt16\"]\n",
    "        trt8 = config[\"trt8\"]\n",
    "\n",
    "        # Paths\n",
    "        dataset_yaml = hyperparams[\"data\"]\n",
    "        model_pt_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best.pt\")\n",
    "        model_trt32_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best_trt_fp32.engine\")\n",
    "        model_trt16_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best_trt_fp16.engine\")\n",
    "        model_trt8_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best_trt_int8.engine\")\n",
    "\n",
    "        validation_params = {\"data\": dataset_yaml, \"device\": \"cuda:0\", \"split\": \"val\"}\n",
    "\n",
    "        if done:\n",
    "            parameters = {\"model_pt_path\": model_pt_path, \"validation_params\": validation_params, \"model_name\": model_name,\n",
    "                          \"dataset_name\": dataset_name, \"optimizer\": optimizer, \"model_format\": \"Pytorch\"}\n",
    "            validate_experiment(dataframe, parameters)\n",
    "        if trt32:\n",
    "            parameters = {\"model_pt_path\": model_trt32_path, \"validation_params\": validation_params, \"model_name\": model_name,\n",
    "                          \"dataset_name\": dataset_name, \"optimizer\": optimizer, \"model_format\": \"TensorRT-F32\"}\n",
    "            validate_experiment(dataframe, parameters)\n",
    "        if trt16:\n",
    "            parameters = {\"model_pt_path\": model_trt16_path, \"validation_params\": validation_params, \"model_name\": model_name,\n",
    "                          \"dataset_name\": dataset_name, \"optimizer\": optimizer, \"model_format\": \"TensorRT-F16\"}\n",
    "            validate_experiment(dataframe, parameters)\n",
    "        if trt8:\n",
    "            parameters = {\"model_pt_path\": model_trt8_path, \"validation_params\": validation_params, \"model_name\": model_name,\n",
    "                          \"dataset_name\": dataset_name, \"optimizer\": optimizer, \"model_format\": \"TensorRT-INT8\"}\n",
    "            validate_experiment(dataframe, parameters)\n",
    "\n",
    "    dataframe.to_csv(results_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.75 ðŸš€ Python-3.10.16 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3060, 11912MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-seg summary (fused): 195 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/memorista01/tesis/datasets_yolo/Deepfish_LO/labels/valid.cache... 66 images, 59 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125         79      0.883      0.953      0.966      0.806      0.925      0.933      0.971      0.761\n",
      "Speed: 0.4ms preprocess, 2.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config_file = \"training/run1.json\"\n",
    "\n",
    "with open(config_file, \"r\") as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "key = \"Deepfish_LO/yolov8n-seg_SGD\"\n",
    "dataset, temp = os.path.split(key)\n",
    "modelo, optimizador = temp.split(\"_\")\n",
    "\n",
    "config = config_dict[key]\n",
    "done = config[\"done\"]\n",
    "trt32 = config[\"trt32\"]\n",
    "trt16 = config[\"trt16\"]\n",
    "trt8 = config[\"trt8\"]\n",
    "hyperparams = config[\"hyperparams\"]\n",
    "\n",
    "# Paths\n",
    "dataset_yaml = hyperparams[\"data\"]\n",
    "model_pt_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best.pt\")\n",
    "model_trt32_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best_trt_fp32.engine\")\n",
    "model_trt16_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best_trt_fp16.engine\")\n",
    "model_trt8_path = os.path.join(hyperparams[\"project\"],hyperparams[\"name\"], \"weights\", \"best_trt_int8.engine\")\n",
    "\n",
    "validation_params = {\"data\": dataset_yaml, \"device\": \"cuda:0\", \"split\": \"val\", \"batch\": 8}\n",
    "\n",
    "if done:\n",
    "    val_results = safe_validate(model_pt_path, validation_params)\n",
    "    data = val_results.results_dict | val_results.speed\n",
    "    cleaned_data = {key.replace(\"metrics/\", \"\"): value for key, value in data.items()}\n",
    "    cleaned_data.update(Model=modelo, Dataset=dataset, Optimizer=optimizador, Format=\"Pytorch\")\n",
    "    row_data = pd.DataFrame([cleaned_data])\n",
    "    dataframe = pd.concat([dataframe, row_data], ignore_index=True)\n",
    "if trt32:\n",
    "    val_results = safe_validate(model_trt32_path, validation_params)\n",
    "    data = val_results.results_dict | val_results.speed\n",
    "    cleaned_data = {key.replace(\"metrics/\", \"\"): value for key, value in data.items()}\n",
    "    cleaned_data.update(Model=modelo, Dataset=dataset, Optimizer=optimizador, Format=\"TensorRT-F32\")\n",
    "    row_data = pd.DataFrame([cleaned_data])\n",
    "    dataframe = pd.concat([dataframe, row_data], ignore_index=True)\n",
    "if trt16:\n",
    "    val_results = safe_validate(model_trt16_path, validation_params)\n",
    "    data = val_results.results_dict | val_results.speed\n",
    "    cleaned_data = {key.replace(\"metrics/\", \"\"): value for key, value in data.items()}\n",
    "    cleaned_data.update(Model=modelo, Dataset=dataset, Optimizer=optimizador, Format=\"TensorRT-F16\")\n",
    "    row_data = pd.DataFrame([cleaned_data])\n",
    "    dataframe = pd.concat([dataframe, row_data], ignore_index=True)\n",
    "if trt8:\n",
    "    val_results = safe_validate(model_trt8_path, validation_params)\n",
    "    data = val_results.results_dict | val_results.speed\n",
    "    cleaned_data = {key.replace(\"metrics/\", \"\"): value for key, value in data.items()}\n",
    "    cleaned_data.update(Model=modelo, Dataset=dataset, Optimizer=optimizador, Format=\"TensorRT-INT8\")\n",
    "    row_data = pd.DataFrame([cleaned_data])\n",
    "    dataframe = pd.concat([dataframe, row_data], ignore_index=True)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
